{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SrKhxzStpDfZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a download link for the 'data.zip' (zipped folder in e2e_project)\n",
    "# and use 'wget' to directly save the data file into Colab's virtual machine.\n",
    "!wget --header=\"Host: doc-0c-6s-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Cookie: AUTH_7hmq5qi5820iffhdqtvl1fasq7mq1eha=13366280707070436374|1530561600000|97r2pdkih8lrft4lld4ik6ultq746h6v\" --header=\"Connection: keep-alive\" \"https://doc-0c-6s-docs.googleusercontent.com/docs/securesc/lftjl6vk3idvd1g2urce9ircg4cv3q5d/oo4ogahq1mk8inu06orl846d59r6d2o3/1530561600000/13366280707070436374/13366280707070436374/1sm_aZu9eMGB0WdCtP678iYYlwGWGsFP2?e=download\" -O \"data.zip\" -c\n",
    "!unzip data.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DDokhcARPf6t"
   },
   "outputs": [],
   "source": [
    "# Execute this section to Set up your Google Drive with Colab. This will help you in saving the model directly to your Google Drive\n",
    "# Reference: https://colab.research.google.com/drive/1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q#scrollTo=c99EvWo1s9-x\n",
    "\n",
    "# Install a Drive FUSE wrapper.\n",
    "# https://github.com/astrada/google-drive-ocamlfuse\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "\n",
    "# Generate auth tokens for Colab\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Generate creds for the Drive FUSE library.\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "# Work around misordering of STREAM and STDIN in Jupyter.\n",
    "# https://github.com/jupyter/notebook/issues/3159\n",
    "prompt = !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass(prompt[0] + '\\n\\nEnter verification code: ')\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "\n",
    "# Create a directory and mount Google Drive using that directory.\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "\n",
    "print('Files in Drive:')\n",
    "!ls drive/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11040,
     "status": "ok",
     "timestamp": 1530589722957,
     "user": {
      "displayName": "Suhan Shetty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108658629281572684125"
     },
     "user_tz": -330
    },
    "id": "XDaI_LesjqjX",
    "outputId": "4ac308dc-14f2-42f4-85c5-f8b2b2b179fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version:  2.1.6\n",
      "Tensorflow Version:  1.9.0-rc1\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import skimage.transform as sktransform\n",
    "from sklearn import model_selection\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "# https://keras.io/\n",
    "!pip install -q keras\n",
    "from keras.callbacks import Callback\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import load_model\n",
    "import math\n",
    "\n",
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "print(\"Keras Version: \",keras.__version__)\n",
    "print(\"Tensorflow Version: \",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BIiBkQHm6bjn"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation, Weight Callbacks\n",
    "\n",
    "# Cameras we will use\n",
    "cameras = ['left', 'center', 'right']\n",
    "cameras_steering_correction = [.25, 0., -.25]\n",
    "\n",
    "def preprocess(image, top_offset=.375, bottom_offset=.125):\n",
    "    \"\"\"\n",
    "    Applies preprocessing pipeline to an image: crops `top_offset` and `bottom_offset`\n",
    "    portions of image, resizes to 32x128 px and scales pixel values to [0, 1].\n",
    "    \"\"\"\n",
    "    top = int(top_offset * image.shape[0])\n",
    "    bottom = int(bottom_offset * image.shape[0])\n",
    "    image = sktransform.resize(image[top:-bottom, :], (32, 128, 3))\n",
    "    return image\n",
    "\n",
    "def generate_samples(data,root_path, bs=128,augment=True):\n",
    "    \"\"\"\n",
    "    Keras generator yielding batches of training/validation data.\n",
    "    Applies data augmentation pipeline if `augment` is True.\n",
    "    \"\"\"\n",
    "    \n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    while True:\n",
    "        # Generate random batch of indices\n",
    "        indices = np.random.permutation(data.count()[0])\n",
    "        batch_size = bs #128\n",
    "\n",
    "        for batch in range(0, len(indices), batch_size):\n",
    "            batch_indices = indices[batch:(batch + batch_size)]\n",
    "            # Output arrays\n",
    "            x = np.empty([0, 32, 128, 3], dtype=np.float32)\n",
    "            y = np.empty([0], dtype=np.float32)\n",
    "            # Read in and preprocess a batch of images\n",
    "\n",
    "            for i in batch_indices:\n",
    "                # Randomly select camera\n",
    "                camera = np.random.randint(len(cameras)) if augment else 1\n",
    "                # Read frame image and work out steering angle\n",
    "                image = mpimg.imread(os.path.join(root_path, data[cameras[camera]].values[i].strip()))\n",
    "                image.setflags(write=1)\n",
    "                #print('Flags: ',image.flags)\n",
    "                angle = data.steering.values[i] + cameras_steering_correction[camera]\n",
    "                if augment:\n",
    "                    # Add random shadow as a vertical slice of image\n",
    "                    h, w = image.shape[0], image.shape[1]\n",
    "                    [x1, x2] = np.random.choice(w, 2, replace=False)\n",
    "                    k = h / (x2 - x1)\n",
    "                    b = - k * x1\n",
    "                    #print('Flags: ',image.flags)\n",
    "                    for i in range(h):\n",
    "                        c = int((i - b) / k)\n",
    "                        image[i, :c, :] = (image[i, :c, :] * .5).astype(np.int32)\n",
    "                        \n",
    "                # Randomly shift up and down while preprocessing\n",
    "                v_delta = .05 if augment else 0\n",
    "                image = preprocess(\n",
    "                    image,\n",
    "                    top_offset=random.uniform(.375 - v_delta, .375 + v_delta),\n",
    "                    bottom_offset=random.uniform(.125 - v_delta, .125 + v_delta)\n",
    "                )\n",
    "                # Append to batch\n",
    "                x = np.append(x, [image], axis=0)\n",
    "                y = np.append(y, [angle])\n",
    "                \n",
    "            # Randomly flip half of images in the batch. Uncomment the following if you want to include flipping.\n",
    "            \n",
    "            #flip_indices = random.sample(range(x.shape[0]), int(x.shape[0] / 2))\n",
    "            #x[flip_indices] = x[flip_indices, :, ::-1, :]\n",
    "            #y[flip_indices] = -y[flip_indices]\n",
    "            yield (x, y)\n",
    "            \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xR28Gl7bxjLw"
   },
   "outputs": [],
   "source": [
    "#Keeps track of model weights by saving them at the end of each epoch.\n",
    "\n",
    "class WeightsLogger(Callback):\n",
    "    def __init__(self, root_path):\n",
    "      super(WeightsLogger, self).__init__()\n",
    "      self.weights_root_path = os.path.join(root_path, 'weights/')\n",
    "      shutil.rmtree(self.weights_root_path, ignore_errors=True)\n",
    "      os.makedirs(self.weights_root_path, exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(os.path.join(self.weights_root_path, 'model_epoch_{}.h5'.format(epoch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1530589733341,
     "user": {
      "displayName": "Suhan Shetty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108658629281572684125"
     },
     "user_tz": -330
    },
    "id": "QoseJMIF3UyE",
    "outputId": "0ff9cd87-2c91-428a-e037-e4a6283e30f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  6219\n",
      "validation:  691\n"
     ]
    }
   ],
   "source": [
    "# Split Training and Validation data\n",
    "\n",
    "local_project_path = ''\n",
    "local_data_path = os.path.join(local_project_path, 'data')\n",
    "\n",
    "sys.path.append(local_project_path) \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Read the data\n",
    "    df = pd.io.parsers.read_csv(os.path.join(local_data_path, 'driving_log.csv'))\n",
    "    # Split data into training and validation sets\n",
    "    df_train, df_valid = model_selection.train_test_split(df, test_size=.1)\n",
    "\n",
    "print(\"train: \",df_train.shape[0])\n",
    "print(\"validation: \",df_valid.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1530589764399,
     "user": {
      "displayName": "Suhan Shetty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108658629281572684125"
     },
     "user_tz": -330
    },
    "id": "QRz_yLVZC6r9",
    "outputId": "98e5dd6d-b6bd-4334-f566-cd22e9727c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network building blocks are ready\n"
     ]
    }
   ],
   "source": [
    "# Network Building blocks\n",
    "\n",
    "def add_denseblock(input, growth_rate = 12, numLayers=12, dropout_rate = 0.2):\n",
    "    temp = input\n",
    "    for _ in range(numLayers):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        conv1xC = Conv2D(growth_rate,(1,3), use_bias=False ,padding='same',dilation_rate=2)(relu)\n",
    "        conv1xCx1 = Conv2D(growth_rate,(3,1), use_bias=False ,padding='same',dilation_rate=2)(conv1xC)\n",
    "        concat = Concatenate(axis=-1)([temp,conv1xCx1])\n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "  \n",
    "def add_transition(input, growth = 16, dropout_rate = 0.2):\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = Conv2D(growth, (1,1), use_bias=False ,padding='same',dilation_rate=2)(relu)\n",
    "    if dropout_rate>0:\n",
    "        Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\n",
    "def output_layer(input):\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "\n",
    "    output = Dense(1,activation='tanh')(flat)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "print(\"Network building blocks are ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 4012
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4566,
     "status": "ok",
     "timestamp": 1530594077095,
     "user": {
      "displayName": "Suhan Shetty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108658629281572684125"
     },
     "user_tz": -330
    },
    "id": "_R0A16yEiykz",
    "outputId": "cbac0a16-a6ee-4d28-f30f-dac781bbdd80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 128, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 32, 128, 14)  378         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 128, 14)  56          conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 32, 128, 14)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 32, 128, 14)  588         activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 32, 128, 14)  588         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 32, 128, 28)  0           conv2d_114[0][0]                 \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 32, 128, 28)  112         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 32, 128, 28)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 32, 128, 14)  1176        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 32, 128, 14)  588         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 32, 128, 42)  0           concatenate_52[0][0]             \n",
      "                                                                 conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 32, 128, 42)  168         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 32, 128, 42)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 32, 128, 14)  1764        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 32, 128, 14)  588         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 32, 128, 56)  0           concatenate_53[0][0]             \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 32, 128, 56)  224         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 32, 128, 56)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 32, 128, 14)  2352        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 32, 128, 14)  588         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 32, 128, 70)  0           concatenate_54[0][0]             \n",
      "                                                                 conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 32, 128, 70)  280         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 32, 128, 70)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 32, 128, 14)  2940        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 32, 128, 14)  588         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 32, 128, 84)  0           concatenate_55[0][0]             \n",
      "                                                                 conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 32, 128, 84)  336         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 32, 128, 84)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 32, 128, 14)  3528        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 32, 128, 14)  588         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 32, 128, 98)  0           concatenate_56[0][0]             \n",
      "                                                                 conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 32, 128, 98)  392         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 32, 128, 98)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 32, 128, 14)  4116        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 32, 128, 14)  588         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 32, 128, 112) 0           concatenate_57[0][0]             \n",
      "                                                                 conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 32, 128, 112) 448         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 32, 128, 112) 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 32, 128, 14)  1568        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 16, 64, 14)   0           conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 64, 14)   56          average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 64, 14)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 16, 64, 10)   420         activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 16, 64, 10)   300         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 16, 64, 24)   0           average_pooling2d_12[0][0]       \n",
      "                                                                 conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 64, 24)   96          concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 16, 64, 24)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 16, 64, 10)   720         activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 16, 64, 10)   300         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 16, 64, 34)   0           concatenate_59[0][0]             \n",
      "                                                                 conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 16, 64, 34)   136         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 64, 34)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 16, 64, 10)   1020        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 16, 64, 10)   300         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 16, 64, 44)   0           concatenate_60[0][0]             \n",
      "                                                                 conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 16, 64, 44)   176         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 16, 64, 44)   0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 16, 64, 10)   1320        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 16, 64, 10)   300         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 16, 64, 54)   0           concatenate_61[0][0]             \n",
      "                                                                 conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 64, 54)   216         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 16, 64, 54)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 16, 64, 10)   1620        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 16, 64, 10)   300         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 16, 64, 64)   0           concatenate_62[0][0]             \n",
      "                                                                 conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 64, 64)   256         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 16, 64, 64)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 16, 64, 10)   1920        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 16, 64, 10)   300         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 16, 64, 74)   0           concatenate_63[0][0]             \n",
      "                                                                 conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 16, 64, 74)   296         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 16, 64, 74)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 16, 64, 10)   2220        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 16, 64, 10)   300         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 16, 64, 84)   0           concatenate_64[0][0]             \n",
      "                                                                 conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 16, 64, 84)   336         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 16, 64, 84)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 16, 64, 10)   2520        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 16, 64, 10)   300         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 16, 64, 94)   0           concatenate_65[0][0]             \n",
      "                                                                 conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 16, 64, 94)   376         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 16, 64, 94)   0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 16, 64, 10)   2820        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 16, 64, 10)   300         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 16, 64, 104)  0           concatenate_66[0][0]             \n",
      "                                                                 conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 16, 64, 104)  416         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 16, 64, 104)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 16, 64, 10)   3120        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 16, 64, 10)   300         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 16, 64, 114)  0           concatenate_67[0][0]             \n",
      "                                                                 conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 16, 64, 114)  456         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 16, 64, 114)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 16, 64, 10)   3420        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 16, 64, 10)   300         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 16, 64, 124)  0           concatenate_68[0][0]             \n",
      "                                                                 conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 16, 64, 124)  496         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 16, 64, 124)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 16, 64, 10)   1240        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 8, 32, 10)    0           conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 32, 10)    40          average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 32, 10)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 4, 16, 10)    0           activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 640)          0           average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            641         flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 54,195\n",
      "Trainable params: 51,511\n",
      "Non-trainable params: 2,684\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define the hyperparameters : growth rate in densenet\n",
    "growth_rate_net1 = 14\n",
    "numLayers_net1 = 7\n",
    "\n",
    "growth_rate_net2 = 10\n",
    "numLayers_net2 = 11\n",
    "\n",
    "dropout_rate = 0.0\n",
    "input_shape=(32, 128, 3)\n",
    "\n",
    "input = Input(shape=input_shape)\n",
    "First_Conv2D = Conv2D(growth_rate_net1, (3,3), use_bias=False ,padding='same',dilation_rate=2)(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, growth_rate_net1, numLayers_net1, dropout_rate)\n",
    "First_Transition = add_transition(First_Block, growth_rate_net1, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, growth_rate_net2, numLayers_net2, dropout_rate) \n",
    "Second_Transition = add_transition(Second_Block, growth_rate_net2, dropout_rate)\n",
    "\n",
    "output = output_layer(Second_Transition)\n",
    "\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1788
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3115261,
     "status": "ok",
     "timestamp": 1530597257246,
     "user": {
      "displayName": "Suhan Shetty",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108658629281572684125"
     },
     "user_tz": -330
    },
    "id": "NrExKS5aKV_v",
    "outputId": "c9534572-fc69-47b1-8f8b-7968ac4bc2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Compilation Successful\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/48 [==============================] - 82s 2s/step - loss: 0.1514 - val_loss: 0.1600\n",
      "Epoch 2/50\n",
      "49/48 [==============================] - 58s 1s/step - loss: 0.0826 - val_loss: 0.0852\n",
      "Epoch 3/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0815 - val_loss: 0.1081\n",
      "Epoch 4/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0768 - val_loss: 0.1022\n",
      "Epoch 5/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0732 - val_loss: 0.0745\n",
      "Epoch 6/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0723 - val_loss: 0.0684\n",
      "Epoch 7/50\n",
      "10/48 [=====>........................] - ETA: 38s - loss: 0.064849/48 [==============================] - 60s 1s/step - loss: 0.0705 - val_loss: 0.0594\n",
      "Epoch 8/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0696 - val_loss: 0.0799\n",
      "Epoch 9/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0711 - val_loss: 0.0868\n",
      "Epoch 10/50\n",
      "49/48 [==============================] - 62s 1s/step - loss: 0.0665 - val_loss: 0.0588\n",
      "Epoch 11/50\n",
      "49/48 [==============================] - 59s 1s/step - loss: 0.0681 - val_loss: 0.0822\n",
      "Epoch 12/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0667 - val_loss: 0.1095\n",
      "Epoch 13/50\n",
      "11/48 [=====>........................] - ETA: 37s - loss: 0.066449/48 [==============================] - 60s 1s/step - loss: 0.0646 - val_loss: 0.0845\n",
      "Epoch 14/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0635 - val_loss: 0.0644\n",
      "Epoch 15/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0645 - val_loss: 0.1057\n",
      "Epoch 16/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0626 - val_loss: 0.0626\n",
      "Epoch 17/50\n",
      "49/48 [==============================] - 59s 1s/step - loss: 0.0643 - val_loss: 0.1089\n",
      "Epoch 18/50\n",
      "49/48 [==============================] - 59s 1s/step - loss: 0.0634 - val_loss: 0.0563\n",
      "Epoch 19/50\n",
      "10/48 [=====>........................] - ETA: 38s - loss: 0.060849/48 [==============================] - 59s 1s/step - loss: 0.0629 - val_loss: 0.0956\n",
      "Epoch 20/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0617 - val_loss: 0.0744\n",
      "Epoch 21/50\n",
      "49/48 [==============================] - 62s 1s/step - loss: 0.0614 - val_loss: 0.0530\n",
      "Epoch 22/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0634 - val_loss: 0.0600\n",
      "Epoch 23/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0606 - val_loss: 0.0958\n",
      "Epoch 24/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0601 - val_loss: 0.1101\n",
      "Epoch 25/50\n",
      "10/48 [=====>........................] - ETA: 38s - loss: 0.060049/48 [==============================] - 60s 1s/step - loss: 0.0568 - val_loss: 0.0580\n",
      "Epoch 26/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0568 - val_loss: 0.0506\n",
      "Epoch 27/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0551 - val_loss: 0.0506\n",
      "Epoch 28/50\n",
      "49/48 [==============================] - 59s 1s/step - loss: 0.0534 - val_loss: 0.0488\n",
      "Epoch 29/50\n",
      "49/48 [==============================] - 62s 1s/step - loss: 0.0546 - val_loss: 0.0515\n",
      "Epoch 30/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0540 - val_loss: 0.0478\n",
      "Epoch 31/50\n",
      "10/48 [=====>........................] - ETA: 38s - loss: 0.056949/48 [==============================] - 61s 1s/step - loss: 0.0540 - val_loss: 0.0492\n",
      "Epoch 32/50\n",
      "49/48 [==============================] - 62s 1s/step - loss: 0.0543 - val_loss: 0.0488\n",
      "Epoch 33/50\n",
      "49/48 [==============================] - 63s 1s/step - loss: 0.0537 - val_loss: 0.0495\n",
      "Epoch 34/50\n",
      "49/48 [==============================] - 62s 1s/step - loss: 0.0532 - val_loss: 0.0532\n",
      "Epoch 35/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0529 - val_loss: 0.0493\n",
      "Epoch 36/50\n",
      "49/48 [==============================] - 62s 1s/step - loss: 0.0533 - val_loss: 0.0513\n",
      "Epoch 37/50\n",
      "10/48 [=====>........................] - ETA: 38s - loss: 0.056349/48 [==============================] - 61s 1s/step - loss: 0.0534 - val_loss: 0.0517\n",
      "Epoch 38/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0529 - val_loss: 0.0535\n",
      "Epoch 39/50\n",
      "49/48 [==============================] - 63s 1s/step - loss: 0.0526 - val_loss: 0.0510\n",
      "Epoch 40/50\n",
      "49/48 [==============================] - 63s 1s/step - loss: 0.0529 - val_loss: 0.0481\n",
      "Epoch 41/50\n",
      "49/48 [==============================] - 63s 1s/step - loss: 0.0514 - val_loss: 0.0486\n",
      "Epoch 42/50\n",
      "49/48 [==============================] - 62s 1s/step - loss: 0.0533 - val_loss: 0.0465\n",
      "Epoch 43/50\n",
      "10/48 [=====>........................] - ETA: 38s - loss: 0.050049/48 [==============================] - 62s 1s/step - loss: 0.0520 - val_loss: 0.0473\n",
      "Epoch 44/50\n",
      "49/48 [==============================] - 62s 1s/step - loss: 0.0528 - val_loss: 0.0565\n",
      "Epoch 45/50\n",
      "49/48 [==============================] - 63s 1s/step - loss: 0.0523 - val_loss: 0.0492\n",
      "Epoch 46/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0525 - val_loss: 0.0546\n",
      "Epoch 47/50\n",
      "49/48 [==============================] - 61s 1s/step - loss: 0.0519 - val_loss: 0.0488\n",
      "Epoch 48/50\n",
      "49/48 [==============================] - 60s 1s/step - loss: 0.0513 - val_loss: 0.0497\n",
      "Epoch 49/50\n",
      "10/48 [=====>........................] - ETA: 38s - loss: 0.054549/48 [==============================] - 60s 1s/step - loss: 0.0518 - val_loss: 0.0472\n",
      "Epoch 50/50\n",
      "49/48 [==============================] - 62s 1s/step - loss: 0.0503 - val_loss: 0.0469\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Learning Rate Schedule\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.005\n",
    "    drop = 0.1\n",
    "    epochs_drop = 25.0\n",
    "    lrate = initial_lrate * math.pow(drop,  \n",
    "    math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "  \n",
    "lrate = LearningRateScheduler(step_decay)  \n",
    "\n",
    "# Determine Loss function and Optimizer\n",
    "\n",
    "adm = keras.optimizers.Adam(lr = 0.0001,beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer=adm)\n",
    "print(\"Model Compilation Successful\")\n",
    "\n",
    "# Training Training\n",
    "\n",
    "epoch = 50\n",
    "batch_size = 128\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generate_samples(df_train,local_data_path, batch_size),\n",
    "    steps_per_epoch=df_train.shape[0]/batch_size,\n",
    "    epochs=epoch,\n",
    "    callbacks=[lrate,WeightsLogger(root_path=local_project_path)],\n",
    "    validation_data=generate_samples(df_valid, local_data_path, augment=False),\n",
    "    validation_steps = df_valid.shape[0]/batch_size,\n",
    "    initial_epoch=0, verbose=1)\n",
    "\n",
    "# Directly save the model to your google drive\n",
    "model.save('drive/model.h5')\n",
    "with open('drive/model.json', 'w') as file:\n",
    "    file.write(model.to_json())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "final_6.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
